@Book{itila,
  author    = {MacKay, David J. C.},
  title     = {{Information Theory, Inference, and Learning Algorithms}},
  year      = {2003},
  publisher = {Cambridge University Press},
  owner     = {deisenroth},
  timestamp = {2007-02-20},
}


@article{vanhorn2003cox,
  title={Constructing a logic of plausible inference: a guide to Coxâ€™s theorem},
  author={Van Horn, Kevin S.},
  journal={International Journal of Approximate Reasoning},
  volume={34},
  number={1},
  pages={3--24},
  year={2003},
  publisher={Elsevier}
}


@article{cox1946,
  title={Probability, frequency and reasonable expectation},
  author={Cox, Richard T.},
  journal={American journal of physics},
  volume={14},
  number={1},
  pages={1--13},
  year={1946},
  publisher={American Association of Physics Teachers}
}

@article{cox1963,
  title={The algebra of probable inference},
  author={Cox, Richard T},
  journal={American Journal of Physics},
  volume={31},
  number={1},
  pages={66--67},
  year={1963},
  publisher={American Association of Physics Teachers}
}

@book{mml,
  title={Mathematics for machine learning},
  author={Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
  year={2020},
  publisher={Cambridge University Press}
}

@book{gpml,
  title={Gaussian processes for machine learning},
  author={Rasmussen, Carl Edward and Williams, Christopher K.I.},
  year=2006,
  publisher={MIT press, Cambridge, MA, USA}
}

@book{murphy,
  title={Machine learning: a probabilistic perspective},
  author={Murphy, Kevin P},
  year={2012},
  publisher={MIT press}
}


@incollection{wang2019gpmillion,
title = {Exact Gaussian Processes on a Million Data Points},
author = {Wang, Ke and Pleiss, Geoff and Gardner, Jacob and Tyree, Stephen and Weinberger, Kilian Q and Wilson, Andrew Gordon},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {14622--14632},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9606-exact-gaussian-processes-on-a-million-data-points.pdf}
}

@incollection{gardner2018,
title = {GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration},
author = {Gardner, Jacob and Pleiss, Geoff and Weinberger, Kilian Q and Bindel, David and Wilson, Andrew G},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {7576--7586},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7985-gpytorch-blackbox-matrix-matrix-gaussian-process-inference-with-gpu-acceleration.pdf}
}

@incollection{wiki:trunc-normal,
title={Truncated normal distribution},
author={Wikipedia},
url={https://en.wikipedia.org/wiki/Truncated_normal_distribution},
booktitle={Wikipedia},
publisher={Wikimedia Foundation},
year=2020,
month=1
}


@book{walpole2012probability,
  title={Probability \& statistics for engineers \& scientists},
  author={Walpole, Ronald E. and Myers, Raymond H.},
  year={2012},
  publisher={Pearson Education Limited}
}

@InCollection{Kim2015,
  author    = {Kim, Been and Shah, Julie A and Doshi-Velez, Finale},
  title     = {{Mind the Gap: A Generative Approach to Interpretable Feature Selection and Extraction}},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2015},
  editor    = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R},
  pages     = {2260--2268},
  url       = {http://papers.nips.cc/paper/5957-mind-the-gap-a-generative-approach-to-interpretable-feature-selection-and-extraction.pdf},
  owner     = {mpd37},
  timestamp = {2017.02.10},
}

@Book{Bishop2006,
  author    = {Bishop, Christopher M.},
  title     = {{Pattern {Recognition and Machine Learning}}},
  year      = {2006},
  series    = {{Information Science and Statistics}},
  publisher = {Springer-Verlag},
  timestamp = {2008.10.01},
}

@Book{Pearl1988,
  Title                    = {{Probabilistic {Reasoning in Intelligent Systems: Networks of Plausible Inference}}},
  Author                   = {Pearl, Judea},
  Publisher                = {Morgan Kaufmann},
  Year                     = {1988},

  ISBN                     = {1558604790},
  Timestamp                = {2009.04.01}
}

@InProceedings{Deisenroth2011,
  Title                    = {{A General Perspective on Gaussian Filtering and Smoothing: Explaining Current and Deriving New Algorithms}},
  Author                   = {Deisenroth, Marc P. and Ohlsson, Henrik},
  Booktitle                = {Proceedings of the American Control Conference},
  Year                     = {2011},

  Timestamp                = {2011.01.20}
}

@Article{Deisenroth2009,
  Title                    = {{Gaussian {Process Dynamic Programming}}},
  Author                   = {Deisenroth, Marc P. and Rasmussen, Carl E. and Peters, Jan},
  Journal                  = {Neurocomputing},
  Year                     = {2009},

  Month                    = mar,
  Number                   = {7--9},
  Pages                    = {1508--1524},
  Volume                   = {72},

  Abstract                 = {Reinforcement learning (RL) and optimal control of systems with continuous states and actions require approximation techniques in most interesting cases. In this article, we introduce Gaussian process dynamic programming (GPDP), an approximate value-function based RL algorithm. We consider both a classic optimal control problem, where problem-specific prior knowledge is available, and a classic RL problem, where only very general priors can be used. For the classic optimal control problem, GPDP models the unknown value functions with Gaussian processes and generalizes dynamic programming to continuous-valued states and actions. For the RL problem, GPDP starts from a given initial state and explores the state space using Bayesian active learning. To design a fast learner, available data has to be used efficiently. Hence, we propose to learn probabilistic models of the a priori unknown transition dynamics and the value functions on the fly. In both cases, we successfully apply the resulting continuous-valued controllers to the under-actuated pendulum swing up and analyze the performances of the suggested algorithms. It turns out that GPDP uses data very efficiently and can be applied to problems, where classic dynamic programming would be cumbersome.},
  Citeseerurl              = {http://www.science-direct.com/science?\_ob=MImg\&\_imagekey=B6V10-4VC0YDJ-2-11\&\_cdi=5660\&\_user=1495569\&\_orig=browse\&\_coverDate=03\%2F31\%2F2009\&\_sk=999279992\&view=c\&wchp=dGLbVlW-zSkWb\&md5=e6894442349ef0ff2bd4026d3d620d6c\&ie=/sdarticle.pdf},
  Doi                      = {10.1016/j.neucom.2008.12.019},
  Timestamp                = {2008.06.16},
  Url                      = {http://mlg.eng.cam.ac.uk/marc/publications/neurocomputing2009_preprint.pdf}
}

@InProceedings{Cutler2015,
  author    = {Cutler, Mark and How, Jonathan P.},
  title     = {Efficient {Reinforcement Learning for Robots using Informative Simulated Priors}},
  booktitle = {Proceedings of the International Conference on Robotics and Automation},
  year      = {2015},
  url       = {http://markjcutler.com/papers/Cutler15_ICRA.pdf},
}

@Book{Cressie1993,
  Title                    = {{Statistics for Spatial Data}},
  Author                   = {Cressie, Noel A. C.},
  Publisher                = {Wiley-Interscience},
  Year                     = {1993},

  Timestamp                = {2009.07.23}
}

@Article{Krause2008,
  Title                    = {{Near-{Optimal Sensor Placements in {Gauss}ian Processes: Theory, Efficient Algorithms and Empirical Studies}}},
  Author                   = {Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2008},

  Month                    = feb,
  Pages                    = {235--284},
  Volume                   = {9},

  Abstract                 = {When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task, for example, geometry or disk models, placing sensors at the points of highest entropy (variance) in the GP model, and A-, D-, or E-optimal design. In this paper, we tackle the combinatorial optimization problem of maximizing the mutual information between the chosen locations and the locations which are not selected. We prove that the problem of finding the configuration that maximizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1-1/e) of the optimum by exploiting the submodularity of mutual information. We also show how submodularity can be used to obtain online bounds, and design branch and bound search procedures. We then extend our algorithm to exploit lazy evaluations and local structure in the GP, yielding significant speedups. We also extend our approach to find placements which are robust against node failures and uncertainties in the model. These extensions are again associated with rigorous theoretical approximation guarantees, exploiting the submodularity of the objective function. We demonstrate the advantages of our approach towards optimizing mutual information in a very extensive empirical study on two real-world data sets.},
  Timestamp                = {2008.05.30},
  Url                      = {http://www.jmlr.org/papers/volume9/krause08a/krause08a.pdf}
}

@Article{Roberts2013,
  Title                    = {{Gaussian {Processes for Time Series Modelling}}},
  Author                   = {Roberts, Stephen and Osborne, Michael A. and Ebden, Mark and Reece, Steven and Gibson, Neale and Aigrain, Suzanne},
  Journal                  = {Philosophical Transactions of the Royal Society (Part A)},
  Year                     = {2013},

  Month                    = feb,
  Number                   = {1984},
  Volume                   = {371},

  Abstract                 = {In this paper, we offer a gentle introduction to Gaussian processes for time-series data analysis. The conceptual framework of Bayesian modelling for time-series data is discussed and the foundations of Bayesian non-parametric modelling presented for Gaussian processes. We discuss how domain knowledge influences design of the Gaussian process models and provide case examples to highlight the approaches.},
  Doi                      = {10.1098/rsta.2011.0550},
  Owner                    = {marc},
  Timestamp                = {2013.11.01},
  Url                      = {http://rsta.royalsocietypublishing.org/content/371/1984/20110550.full.pdf+html}
}

@InCollection{Frigola2013,
  author    = {Frigola, Roger and Lindsten, Fredrik and Sch\"{o}n, Thomas B and Rasmussen, Carl Edward},
  title     = {Bayesian {Inference and Learning in Gaussian Process State-Space Models with Particle MCMC}},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2013},
  editor    = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  pages     = {3156--3164},
  url       = {http://papers.nips.cc/paper/5085-bayesian-inference-and-learning-in-gaussian-process-state-space-models-with-particle-mcmc.pdf},
  owner     = {marc},
  timestamp = {2017.02.12},
}

@Article{Deisenroth2012,
  Title                    = {{Robust {Filtering and Smoothing with {Gauss}ian Processes}}},
  Author                   = {Deisenroth, Marc P. and Turner, Ryan and Huber, Marco and Hanebeck, Uwe D. and Rasmussen, Carl E.},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {2012},
  Number                   = {7},
  Pages                    = {1865--1871},
  Volume                   = {57},

  Doi                      = {10.1109/TAC.2011.2179426},
  Timestamp                = {2011.01.20}
}

@InProceedings{Osborne2008,
  author    = {Osborne, Michael A. and Roberts, Stephen J. and Rogers, Alex and Ramchurn, Sarvapali D. and Jennings, Nick R.},
  title     = {Towards {Real-Time Information Processing of Sensor Network Data Using Computationally Efficient Multi-output Gaussian Processes}},
  booktitle = {Proceedings of the International Conference on Information Processing in Sensor Networks},
  year      = {2008},
  publisher = {IEEE Computer Society},
  isbn      = {978-0-7695-3157-1},
  pages     = {109--120},
  doi       = {10.1109/IPSN.2008.25},
  url       = {http://dx.doi.org/10.1109/IPSN.2008.25},
  acmid     = {1372727},
  keywords  = {sensor network, Gaussian processes, information processing},
  numpages  = {12},
  owner     = {marc},
  timestamp = {2017.02.13},
}

@Unpublished{Bertone2016,
  Title                    = {Accelerating {the BSM Interpretation of LHC Data with Machine Learning}},
  Author                   = {Bertone, Gianfranco and Deisenroth, Marc P. and Kim, Jong S. and Liem, Sebastian and de Austri, Roberto R. and Welling, Max},
  Note                     = {arXiv preprint arXiv:1611.02704},
  Year                     = {2016},

  Journal                  = {arXiv preprint arXiv:1611.02704}
}

@InProceedings{Deisenroth2011b,
  author    = {Deisenroth, Marc P. and Rasmussen, Carl E. and Fox, Dieter},
  title     = {{Learning {to Control a Low-Cost Manipulator using Data-Efficient Reinforcement Learning}}},
  booktitle = {{Proceedings of Robotics: Science and Systems}},
  year      = {2011},
  url       = {http://www.roboticsproceedings.org/rss07/p08-pdf.html},
  abstract  = {Over the last years, there has been substantial progress in robust manipulation in unstructured environments. The long-term goal of our work is to get away from precise, but very expensive robotic systems and to develop affordable, potentially imprecise, self-adaptive manipulator systems that can interactively perform tasks such as playing with children. In this paper, we demonstrate how a low-cost off-the-shelf robotic system can learn closed-loop policies for a stacking task in only a handful of trials-from scratch. Our manipulator is inaccurate and provides no pose feedback. For learning a controller in the work space of a Kinect-style depth camera, we use a model-based reinforcement learning technique. Our learning method is data efficient, reduces model bias, and deals with several noise sources in a principled way during long-term planning. We present a way of incorporating state-space constraints into the learning process and analyze the learning gain by exploiting the sequential structure of the stacking task.},
  timestamp = {2011.01.20},
}

@inproceedings{germain2016pac,
 author = {Germain, Pascal and Bach, Francis and Lacoste, Alexandre and Lacoste-Julien, Simon},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {1884--1892},
 publisher = {Curran Associates, Inc.},
 title = {PAC-Bayesian Theory Meets Bayesian Inference},
 url = {https://proceedings.neurips.cc/paper/2016/file/84d2004bf28a2095230e8e14993d398d-Paper.pdf},
 volume = {29},
 year = {2016}
}

@book{russell,
  title={Artificial intelligence a modern approach},
  author={Russell, Stuart J},
  year={2010},
  publisher={Pearson Education, Inc.}
}

